<message message-id="49E7384B.5020707@trash.net" list="org.kernel.vger.netdev" id="24bqmrjgh4pqmxo7" type="development" date="2009-04-16T05:53:11.404237-08:00" year="2009-01-01" year-month="2009-04-01" year-month-day="2009-04-16" thread-id="2crmw5ykpdoxevgo"><headers><envelope-from-line>Thu Apr 16 05:53:34 2009</envelope-from-line><from personal="Patrick McHardy" address="kaber@trash.net">Patrick McHardy &lt;kaber@trash.net&gt;</from><to personal="Eric Dumazet" address="dada1@cosmosbay.com">Eric Dumazet &lt;dada1@cosmosbay.com&gt;</to><cc personal="Stephen Hemminger" address="shemminger@vyatta.com">Stephen Hemminger &lt;shemminger@vyatta.com&gt;</cc><subject normal="[PATCH] netfilter: use per-cpu spinlock and RCU (v5)">Re: [PATCH] netfilter: use per-cpu spinlock and RCU (v5)</subject><received>from srv-117c-be06.markmail.marklogic.com ([172.19.8.46])
          by mail-1.a.markmail.int (JAMES SMTP Server 2.3.1) with SMTP ID 196
          for &lt;lesa.figueroa.barnes@a.markmail.org&gt;;
          Thu, 16 Apr 2009 05:53:34 -0800 (GMT-08:00)</received><received>from vger.kernel.org (slb-117n.markmail.marklogic.com [172.19.8.33])
	by mgw-1.public.markmail.int (Postfix) with ESMTP id DC2472908065
	for &lt;lesa.figueroa.barnes@a.markmail.org&gt;; Thu, 16 Apr 2009 06:53:10 -0700 (PDT)</received><received>(majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756075AbZDPNxY (ORCPT
	&lt;rfc822;lesa.figueroa.barnes@a.markmail.org&gt;);
	Thu, 16 Apr 2009 09:53:24 -0400</received><received>(majordomo@vger.kernel.org) by vger.kernel.org id S1753133AbZDPNxW
	(ORCPT &lt;rfc822;netdev-outgoing&gt;); Thu, 16 Apr 2009 09:53:22 -0400</received><received>from stinky.trash.net ([213.144.137.162]:57048 "EHLO
	stinky.trash.net" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752282AbZDPNxV (ORCPT
	&lt;rfc822;netdev@vger.kernel.org&gt;); Thu, 16 Apr 2009 09:53:21 -0400</received><received>from [192.168.0.100] (unknown [78.42.204.165])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by stinky.trash.net (Postfix) with ESMTPSA id 3C303948AB;
	Thu, 16 Apr 2009 15:53:17 +0200 (MEST)</received><message-id>49E7384B.5020707@trash.net</message-id><date>Thu, 16 Apr 2009 15:53:15 +0200</date><user-agent>Mozilla-Thunderbird 2.0.0.19 (X11/20090103)</user-agent><mime-version>1.0</mime-version><references>&lt;49E5BDF7.8090502@trash.net&gt;	&lt;20090415135526.2afc4d18@nehalam&gt;	&lt;49E64C91.5020708@cosmosbay.com&gt;	&lt;20090415.164811.19905145.davem@davemloft.net&gt;	&lt;20090415170111.6e1ca264@nehalam&gt;	&lt;alpine.LFD.2.00.0904151705120.4042@localhost.localdomain&gt; &lt;20090415174551.529d241c@nehalam&gt; &lt;49E6BBA9.2030701@cosmosbay.com&gt;</references><in-reply-to>&lt;49E6BBA9.2030701@cosmosbay.com&gt;</in-reply-to><content-type>text/plain; charset=ISO-8859-15; format=flowed</content-type><sender>netdev-owner@vger.kernel.org</sender><precedence>bulk</precedence><list-id>&lt;netdev.vger.kernel.org&gt;</list-id><x-mailing-list>netdev@vger.kernel.org</x-mailing-list><content-transfer-encoding>quoted-printable</content-transfer-encoding></headers><normalized-references><normalized-message-id>49E7384B.5020707@trash.net</normalized-message-id><normalized-in-reply-to>49E6BBA9.2030701@cosmosbay.com</normalized-in-reply-to><normalized-reference>49E5BDF7.8090502@trash.net</normalized-reference><normalized-reference>20090415135526.2afc4d18@nehalam</normalized-reference><normalized-reference>49E64C91.5020708@cosmosbay.com</normalized-reference><normalized-reference>20090415.164811.19905145.davem@davemloft.net</normalized-reference><normalized-reference>20090415170111.6e1ca264@nehalam</normalized-reference><normalized-reference>alpine.LFD.2.00.0904151705120.4042@localhost.localdomain</normalized-reference><normalized-reference>20090415174551.529d241c@nehalam</normalized-reference><normalized-reference>49E6BBA9.2030701@cosmosbay.com</normalized-reference></normalized-references><body type="text/plain; charset=iso-8859-15; format=flowed"><para depth="0">Eric Dumazet wrote:
</para><quote depth="1"><quotepara depth="1">Stephen Hemminger a Ã©crit :
</quotepara><quote depth="2"><quotepara depth="2">This is an alternative version of ip/ip6/arp tables locking using
per-cpu locks.  This avoids the overhead of synchronize_net() during
update but still removes the expensive rwlock in earlier versions.

</quotepara><quotepara depth="2">The idea for this came from an earlier version done by Eric Dumazet.
Locking is done per-cpu, the fast path locks on the current cpu
and updates counters.  The slow case involves acquiring the locks on
all cpu's. This version uses RCU for the table-&gt;base reference
but per-cpu-lock for counters.
</quotepara></quote></quote><para depth="0">
</para><quote depth="1"><quotepara depth="1">This version is a regression over 2.6.2[0-9], because of two points

</quotepara><quotepara depth="1">1) Much more atomic ops :

</quotepara><quotepara depth="1">Because of additional

</quotepara><quote depth="2"><quotepara depth="2">+			spin_lock(&amp;__get_cpu_var(ip_tables_lock));
 			ADD_COUNTER(e-&gt;counters, ntohs(ip-&gt;tot_len), 1);
+			spin_unlock(&amp;__get_cpu_var(ip_tables_lock));
</quotepara></quote><quotepara depth="1">
added on each counter updates.

</quotepara><quotepara depth="1">On many setups, each packet coming in or out of the machine has
to update between 2 to 20 rule counters. So to avoid *one* atomic ops
of read_unlock(), this v4 version adds 2 to 20 atomic ops...
</quotepara></quote><para depth="0">
I agree, this seems to be a step backwards.

</para><quote depth="1"><quotepara depth="1">I still not see the problem between the previous version (2.6.2[0-8]) that had a<br/>central
 rwlock, that hurted performance on SMP because of cache line ping pong, and the<br/>solution
having one rwlock per cpu.

</quotepara><quotepara depth="1">We wanted to reduce the cache line ping pong first. This *is* the hurting point,
by an order of magnitude.
</quotepara></quote><para depth="0">
Dave doesn't seem to like the rwlock approach. I don't see a way to
do anything asynchronously like call_rcu() to improve this, so to
bring up one of Stephens suggestions again:

</para><quote depth="1"><quote depth="2"><quote depth="3"><quotepara depth="3">  * use on_each_cpu() somehow to do grace periood?
</quotepara></quote></quote></quote><para depth="0">
We could use this to replace the counters, presuming it is
indeed faster than waiting for a RCU grace period.

</para><quote depth="1"><quotepara depth="1">2) Second problem : Potential OOM

</quotepara><quotepara depth="1">About freeing old rules with call_rcu() and/or schedule_work(), this is going
to OOM pretty fast on small appliances with basic firewall setups loading
rules one by one, as done by original topic reporter.

</quotepara><quotepara depth="1">We had reports from guys using linux with 4MB of available ram (French provider<br/>free.fr on
their applicance box), and we had to use SLAB_DESTROY_BY_RCU thing on conntrack
 to avoid OOM for their setups. We dont want to use call_rcu() and queue 100 or<br/>200 vfree().
</quotepara></quote><para depth="0">
Agreed.
</para><footer type="list-management" depth="0">--
To unsubscribe from this list: send the line "unsubscribe netdev" in
the body of a message to <email>majordomo@vger.kernel.org</email>
More majordomo info at  <url>http://vger.kernel.org/majordomo-info.html</url>
</footer></body></message>